### 概述
#### 基础特征
###### 1.并发
并发是指同一时间段内，一个核心同时接收多个任务，通过引进进程和线程实现;    
并行是指同一时间段内, 多个核心同时处理多个任务，通过硬件如多流水线，多核处理器或分布式计算系统;   

###### 2.共享
共享是指系统中的资源可以被多个并发线程共同使用。    
有两种共享方式：互斥共享、同时共享。    
互斥共享的资源称为临界资源，例如打印机等，同一时间只允许一个进程访问，需要同步机制来实现互斥共享。   

###### 3.虚拟
虚拟技术把一个物理实体转换为多个逻辑实体。   
主要有两种虚拟技术：时分复用技术和空分复用技术。    
多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一个小时间片并快速切换。   
虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内页中。

###### 4.异步
异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。


#### 基础功能
###### 1.进程管理
进程控制、同步、通信，死锁处理，处理机调度等。

###### 2.内存管理
内存分配、地址映射、内存保护与共享、虚拟内存等。

###### 3.文件管理
文件存储空间的管理、目录管理、文件读写管理和保护等。

###### 4.设备管理
完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。    
主要包括缓冲管理、设备分配、设备处理、虚拟设备等。


#### 系统调用
如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。
![](assets/计算机操作系统-e2153120.png)

Linux 的系统调用主要有以下：   

Task | Commond
- | -
进程控制 | fork(); exit(); wait();
进程通信 | pipe(); shmget(); mmap();
文件操作 | open(); read(); write();
设备操作 | ioctl(); read(); write();
信息维护 | getpid(); alarm(); sleep();
安全权限 | chomode(); umask(); chown();

#### 宏内核和微内核
###### 1.宏内核
宏内核是将操作系统功能作为一个紧密结合的整体放到内核中。    
由于各模块共享信息，所以性能较高。

###### 2.微内核
由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，互相独立。    
在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。   
因为频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。
![](assets/计算机操作系统-8f3cfec0.png)

#### 中断分类
###### 1.外中断
由 CPU 执行指令之外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。   
此外还有时钟中断、控制台中断等。

###### 2.异常
由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算数溢出等。

###### 3.陷入
在用户程序中使用系统调用。


### 进程管理
#### 进程和线程
###### 1.进程
进程是资源分配的基本单位。   
进程控制块 (PCB, Process Control Block) 描述进程的基本信息和运行状态, 所谓创建进程和撤销进程都是指对 PCB 的操作。   
进程可以并发的执行。
![](assets/计算机操作系统-a0efb514.png)

###### 2.线程
线程是独立调度的基本单位。   
一个进程可以有多个线程，他们共享进程资源。   

###### 3.区别
>资源：   

进程是分配资源的基础单位，线程不拥有资源，但是可以访问进程拥有的资源。

>调度：

线程是独立调度的基本单位。   
统一进程中切换线程不会导致进程的切换;
一个进程的线程切换到另一个进程的线程时，会引起进程切换。

>系统开销：   

由于创建或撤销进程时，系统都要为止分配或回收资源，如内存空间， I/O 设备等，开销远远高于创建或者撤销线程时的开销。   
进行进程切换时，设计当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换只需要保存和设置少量的寄存器内容，开销很小。

>通信方面

线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC 。


#### 进程状态的切换
![](assets/计算机操作系统-2ea9cf20.png)

* 就绪状态 (ready) : 等待被调度
* 运行状态 (running)
* 阻塞状态 (waiting) : 等待资源

应该注意以下内容：
* 只有就绪态和运行态可以相互转换，其他的都是单向转换。就绪状态的进程通过调度算法获取 CPU 时间，转换为运行态；运行态的进程用完分配的时间片后就会进入就绪态，等待下一次调度。
* 阻塞态是由于缺少资源从运行态转变的，缺少的资源中不包括 CPU 时间，否则会转换为就绪态。

#### 进程调度算法
不同环境的调度算法目标不同，需要针对不同环境讨论调度算法。
##### 1.批处理系统
批处理系统没有太多用户操作，调度算法的目标是保证吞吐量和周转时间 (提交到终止的时间) 。
###### 1.1 先来先服务 (First-come First-serverd, FCFS)
非抢占式的调度算法，按照请求的顺序进行调度。    
有利于长作业，不利于短作业，因为短作业必须必须一致等待前面的长作业执行完毕才能执行。

###### 1.2 短作业优先 (Shortest Job First, SJF)
非抢占式的调度方法，按估计运行时间最短的顺序进行调度。   
如果一直有短作业进入，那么长作业将永远得不到调度。

###### 1.3 最短剩余时间优先 (Shortest Remaining Time Next, SRTN)
最短作业优先的抢占模式，按剩余运行时间的顺序进行调度。   
当新作业到达时，将其运行时间和当前进程的剩余时间进行比较。   
如果新的作业需要时间更少，则挂起当前作业，运行新作业，否则新的作业等待。

##### 2.交互式系统
交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。
###### 2.1 时间片轮转
将所有就绪进程按 FCFS 的原则排查队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行并将其送入就绪队列的队尾，同时将 CPU 时间分配给队首的进程。   
时间片轮转算法的效率和时间片的大小有很大关系：
* 因为进程切换都要保存进程的信息并且载入新进程的信息，若果时间片太短，导致进程切换频繁，导致真正处理任务的时间占比变小。
* 而时间片过长，那么实时性就得不到保障。
![](assets/计算机操作系统-6b825a86.png)

###### 2.2 优先级调度
为每个进程分配一个优先级，按优先级进行调度。    
为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

###### 2.3 多级反馈队列
一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，需要交换 100 次。   
多级队列设置了多个列，每个队列的时间片大小不同，例如1，2，4，8...    
进程在第一个队列没有执行完，就会被移动到下一个队列。这样下来，该进程现在只需要切换7次进程。    
每个队列优先权也不同，最上面优先权最高。只有上一个队列没有进程在排队，才能调度当前队列的进程。     
可以理解成时间片轮转调度和优先级调度的结合。    
![](assets/计算机操作系统-894c5eb1.png)

##### 3.实时系统
实时系统要求一个请求在一个确定的时间内得到响应。
分为硬实时和软实时，前者必须绝对满足截止时间，后者可以容忍一定程度的超时。


#### 进程同步
###### 1.临界区
对临界资源进行访问的代码叫临界区。为了互斥访问临界资源，每个进程进入临界区之前都要进行检查。     

    // entry section
    // critical section
    // exit section

###### 2.同步和互斥
* 同步：多个进程因为合作关系产生的直接制约关系，使得进程有一定的先后执行关系。
* 互斥：多个进程同一时刻只有一个进程可以进入临界区

###### 3.信号量
* up：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作
* down：如果信号量大于 0，执行 -1 操作；如果信号量等于 0，进行睡眠，等待信号量大于 0

down 和 up 操作需要被设计成原语，不可分割，通常做法就是执行操作时屏蔽中断。    
如果信号量只能为 0 和 1，那么就成为了 **互斥量 (Mutex)**, 0 表示临界区已加锁，1 表示临界区解锁。

    typedef int semaphore;
    semaphore mutex = 1;
    void P1() {
      down(&mutex);
      // 临界区
      up(&mutex);
    }

    void P2() {
      down(&mutex);
      // 临界区
      up(&mutex);
    }

>使用信号量实现生产者-消费者问题

问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。

为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。

注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。

    #define N 100
    typedef int semaphore;
    semaphore mutex = 1;
    semaphore empty = N;
    semaphore full = 0;

    void producer() {
      while(TRUE) {
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
      }
    }

    void consumer() {
      while(TRUE) {
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
      }
    }

###### 4.管程
使用信号量机制实现生产者-消费者问题需要客户端做很多控制，而管程吧控制代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。    
C 语言不支持管程，下列代码使用类 Pascal来描述管程。    
示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。   

    monitor ProducerConsumer
      integer i;
      condition c;

      procedure insert();
      begin
      // ...
      end;

      procedure remove();
      begin
      // ...
      end;
    end monitor;

管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。

管程引入了 **条件变量** 以及相关的操作：wait() 和 signal() 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。

>使用管程实现生产者-消费者问题

    // 管程
    monitor ProducerConsumer
      condition full, empty;
      integer count := 0;
      condition c;

      procedure insert(item: integer);
      begin
          if count = N then wait(full);
          insert_item(item);
          count := count + 1;
          if count = 1 then signal(empty);
      end;

      function remove: integer;
      begin
          if count = 0 then wait(empty);
          remove = remove_item;
          count := count - 1;
          if count = N -1 then signal(full);
      end;
    end monitor;

    // 生产者客户端
    procedure producer
    begin
      while true do
      begin
          item = produce_item;
          ProducerConsumer.insert(item);
      end
    end;

    // 消费者客户端
    procedure consumer
    begin
      while true do
      begin
          item = ProducerConsumer.remove;
          consume_item(item);
      end
    end;

#### 经典同步问题
###### 1.哲学家进餐问题
![](assets/计算机操作系统-f691c0ab.png)

五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

下面是一种错误的解法，如果所有哲学家同时拿起左手边的筷子，那么所有哲学家都在等待其它哲学家吃完并释放自己手中的筷子，导致死锁。

    #define N 5
    void philosopher(int i) {
      while(TRUE) {
          think();
          take(i);       // 拿起左边的筷子
          take((i+1)%N); // 拿起右边的筷子
          eat();
          put(i);
          put((i+1)%N);
      }
    }

为了防止死锁的发生，可以设置两个条件：
* 必须同时拿起左右两根筷子；
* 只有在两个邻居都没有进餐的情况下才允许进餐。


    #define N 5
    #define LEFT (i + N - 1) % N // 左邻居
    #define RIGHT (i + 1) % N    // 右邻居
    #define THINKING 0
    #define HUNGRY   1
    #define EATING   2
    typedef int semaphore;
    int state[N];                // 跟踪每个哲学家的状态
    semaphore mutex = 1;         // 临界区的互斥，临界区是 state 数组，对其修改需要互斥      
    semaphore s[N];              // 每个哲学家一个信号量

    void philosopher(int i) {
      while(TRUE) {
          think(i);
          take_two(i);
          eat(i);
          put_two(i);
      }
    }

    void take_two(int i) {
      down(&mutex);
      state[i] = HUNGRY;
      check(i);
      up(&mutex);
      down(&s[i]);               // 只有收到通知之后才可以开始吃，否则会一直等下去
    }

    void put_two(i) {
      down(&mutex);
      state[i] = THINKING;
      check(LEFT);               // 尝试通知左右邻居，自己吃完了，你们可以开始吃了
      check(RIGHT);
      up(&mutex);
    }

    void eat(int i) {
      down(&mutex);
      state[i] = EATING;
      up(&mutex);
    }

    // 检查两个邻居是否都没有用餐，如果是的话，就 up(&s[i])，使得 down(&s[i]) 能够得到通知并继续执行   
    void check(i) {        
      if(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING) {
          state[i] = EATING;
          up(&s[i]);
      }
    }

#### 进程通信
进程同步与进程通信很容易混淆，区别在于：
* 进程同步：控制多个进程按一定顺序执行；
* 进程通信：进程间传输信息。

进程通信是一种手段，进程同步是一种目的。为了让达到进程同步的目的，要让进程间进行通信，传输一些进程同步所需要的信息。

###### 1.管道
管道是通过调用 pipe 函数创建的， fd[0] 用于度， fd[1] 用于写。

    #include <unistd.h>
    int pipe(int fd[2]);

它具有以下限制：
* 只支持半双工通信 (单向交替传输)
* 只能在父子进程或者兄弟进程中使用
![](assets/计算机操作系统-c249749b.png)

###### 2.FIFO
也成为命名管道，去除了管道只能在父子进程中使用的限制。

    #include <sys/stat.h>
    int mkfifo(const char *path, mode_t mode);
    int mkfifoat(int fd, const char *path, mode_t mode);

FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。
![](assets/计算机操作系统-b4db8a17.png)

###### 3.消息队列
相比于 FIFO，消息队列有以下优点：
* 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
* 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
* 读进程可以根据消息类型有选择的接收消息，不像 FIFO 只能默认接收

###### 4.信号量
他是一个计数器，用于为多个进程提供对共享数据对象的访问。

###### 5.共享存储
允许多个进程共享一个给定的存储区。因为数据不需要在进程之间赋值，所以这是最快的一种 IPC 。   
需要信号量来同步对共享数据存储的访问。   
多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

###### 6.套接字
与其他通信机制不同的是，它可用于不同机器的进程通信。


### 死锁
#### 必要条件
![](assets/计算机操作系统-c91d29eb.png)

* 互斥：每个资源要么已经分配给一个进程，要么是可用的
* 等待和占有：已经得到了某个资源的进程可以再请求新的资源
* 不可抢占：已经分配给一个进程的资源不能强制被抢占，它只能被占有它的进程显式地释放。
* 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程锁占有的资源。

#### 处理方法
主要有以下四种方法：
* 鸵鸟策略
* 死锁检测和死锁恢复
* 死锁预防
* 死锁避免

#### 鸵鸟策略
假装无事发生。
因为解决死锁代价很大，因此不处理反而会获得更高的性能。
当发生死锁不会对用户造成多大影响或者发生概率很低的时候可以采用鸵鸟策略。
大多数操作系统，Unix，Linux 和 windows 处理死锁就是忽略它

#### 死锁检测和死锁恢复
不是图阻止死锁，而是当检测到死锁发生时，才去措施进行恢复。
###### 1.每种类型一个资源的死锁检测
![](assets/计算机操作系统-795aba3c.png)

上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。图 a 可以抽取出换，如图 b ，它满足了环路等待条件， 因此会发生死锁。    
每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点触发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。

###### 2.每种类型多个资源的死锁检测
![](assets/计算机操作系统-988a94b6.png)

上图中，有三个进程四个资源，每个数据代表的含义如下：
* E 向量：资源总量
* A 向量：资源剩余量
* C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量
* R 矩阵：每个进程请求的资源数量

进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 的拥有的资源，此时 A = (2 2 2 0)。   
P2 可以执行，执行后释放 P2 拥有的资源， A = (4 2 2 1)。    
P1 也可以执行。 所有程序可以执行，没有死锁。

算法总结如下：   
每个进程最开始都不被标记，执行过程中有可能被标记。 当算法结束时，任何没有被标记的进程都是死锁进程。

    1.寻找一个没有标记的进程 P1 ，它所请求的资源小于等于 A
    2.如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中， 标记该进程，并转向1
    3.如果没有这样一个进程，算法终止

###### 3.死锁恢复
* 利用抢占恢复
* 利用回滚恢复
* 通过杀死进程恢复

#### 死锁预防
在运行程序之前预防发生死锁。

###### 1.破坏互斥条件
例如假脱机打印技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

###### 2.破坏占有和等待条件
一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。

###### 3.破坏不可抢占条件

###### 4.破坏环路等待
给资源统一编号，进程只能按编号顺序来请求资源。

#### 死锁避免
在程序运行时避免发生死锁。
###### 1.安全状态
![](assets/计算机操作系统-6ad7486d.png)

图 a 的第二列 Has 表示已拥有的资源数， 第三列 Max 表示总共需要的资源数， Free 表示还有可以使用的资源数。 从图 a 开始出发，先让 B 拥有所需的所有资源 (图 b)，运行结束后释放 B，此时 Free 变为 5 (图 c)；接着以同样的方式运行 C 和 A ，是的所有进程都成功运行，因此可以称图 a 所示的状态是安全的。

> 如果没有死锁发生，并且即使所有的进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则该状态是安全的

安全状态的检测和死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法和死锁检测算法类似，可供参考。

###### 2.单个资源的银行家算法
一个银行家向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，拒绝请求；否则予以分配。
![](assets/计算机操作系统-9d6bb324.png)

上图中，c 为不安全状态，因此算法会拒绝之前的请求，必然进入图 c 的状态。

###### 3.多个资源的银行家算法
![](assets/计算机操作系统-32a6b134.png)

上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。   
最右边的 E、P、A 分别代表总资源，已分配资源以及可用资源，注意这三个是向量，而不是具体数值。，例如 A = (1020)， 表示 4 个资源分别还剩下 1/0/2/0。

检查一个状态是否安全的算法如下：
* 查找右边的矩阵是否存在一行小于等于向量 A。 如果不存在这样的行，那么系统将会发生死锁，状态是不安全的
* 加入找到这样一行，将该进程标记为终止，并将其已分配资源加载到 A 中
* 重复以上两步，知道所有进程都标记为终止，则状态是安全的。

如果一个状态不是安全的，需要拒绝进入该状态。

### 内存管理
#### 虚拟内存
虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。   
为了更好地管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块成为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存的页时，由硬件执行必要的映射，将确实的部分装入物理内存并重新执行失败的指令。   
从上面的描述中可以看出，虚拟内存允许程序不用将地址空间的每一页都映射到物理内存，也就是说每一个程序不需要全部调入内存就可以运行，这使得优先的内存运行大程序成为可能。例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0 ~ 64K . 该计算机只有 32 KB 的物理内存， 虚拟内存技术允许该计算机运行一个 64 KB 大小的程序。
![](assets/计算机操作系统-b77065e4.png)


#### 分页系统地址映射
内存管理单元 (MMU) 管理着地址空间和物理内存的转换，其中的页表 (Page table) 存储着页 (程序内存空间) 的映射。    
一个虚拟地址分成两个部分。一部分存储页面号，一部分存储偏移量。   
下图的页标存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址 (0010 000000000100) , 前 4 位是存储页面号 2 ， 读取表项内容为 (1101) ，页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 (1100000000000100) 。
![](assets/计算机操作系统-7819baca.png)

#### 页面置换算法
在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。   
此时如果内存已无剩余空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出地方。    
页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。    
页面置换算法的主要目标是使页面置换频率最低 (也可以说缺页率最低)。

###### 1.最佳 (OPT, Optimal Replacement Algorithm)
所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。
是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。    
举例：iyge系统为某进程分配了三个物理块，并有如下页面引用序列：
> 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1

开始运动时，先将 7，0，1 三个页面装入内存，当进程访问页面 2 时发生缺页中断，会将 7 换出，因为此时页面 7 的再次访问时间最长。

###### 2.最近最优未使用 (LRU, Latest Recently Used)
虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。 LRU 将最近最久未使用的页面换出。    
为了实现 LRU ，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表头。这就能保证链表尾的页面是最近最久未被使用的。   
因为每次都要跟新链表，所以实现代价很高。    
> 4, 7, 0, 7, 1, 0, 1, 2, 2, 1, 2, 6

![](assets/计算机操作系统-09c1afe7.png)

###### 3.最近未使用 (NRU, Not Recently Used)
每个页面都有两个状态位，R 与 M，当页面被访问时设置 R = 1，当页面被修改时设置 M = 1。    
其中 R 位会定时清零。可以将页面分成以下四类：
* R = 0，M = 0
* R = 0, M = 1
* R = 1, M = 0
* R = 1, M = 1

当发生缺页中断时，NRU 算法随机从类编号最小的非空类挑选一个页面将它换出。    
NRU 优先换出已被修改的脏页面 (R = 0, M = 1)，而不是频繁使用的干净页面 (R = 1, M = 0).

###### 4.先进先出 (FIFO, First In First Out)
换出最先进入的页面。    
会导致经常被访问的页面缓存，导致缺页率升高。

###### 5.第二次机会算法
FIFO 算法可能会将经常使用的页面换出，为避免该问题，做一个简单修改。    
当页面被访问(读或写)时，设置该页面 R 为 1. 需要替换的时候，检查最老页面的 R 位，如果 R 是 0 则可以替换；否则，将 R 清零 ，并将页面放到链表微端，修改装入时间使其像刚装入一样，然后继续从头部开始搜索。
![](assets/计算机操作系统-d99abffc.png)

###### 6.时钟
第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。
![](assets/计算机操作系统-ecbfd0fa.png)

#### 分段
虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。   
下图为一个编译器在编译过程中建立的多个表，有四个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。
![](assets/计算机操作系统-92d85495.png)

分段的做法是把每个表分成段，一个段构成一个独立的地址空间。 每个段的长度可以不同，并且可以动态增长。
![](assets/计算机操作系统-244a1469.png)

#### 段页式
程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既有分段系统的共享和保护，又有分页系统的虚拟内存功能。

#### 分页和分段的比较
* 对程序员的透明性：分页透明，分段需要程序员显式划分每个段
* 地址空间的维度：分也是一维地址空间，分段是二维的
* 大小是否可以改变：页的大小不可变，段可以动态改变
* 出现原因：分页主要用于实现虚拟内存，获得更大地址空间；分段主要是使程序和数据可以被划分成逻辑上独立的地址空间并有助于共享和保护
